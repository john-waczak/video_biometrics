{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import cv2\n",
    "from getFacialLandmarksSingleImage import *\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'image', 'emotion'], dtype='object') (35882, 3)\n"
     ]
    }
   ],
   "source": [
    "dataPath = \"/media/john/Data/datasets/facial-expressions/metadata_processed.csv\"\n",
    "data = pd.read_csv(dataPath)\n",
    "print(data.columns, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sad' 'Angry' 'Disgust' 'Fear' 'Surprise' 'Neutral' 'Happy']\n"
     ]
    }
   ],
   "source": [
    "# these are the labels for the dataset\n",
    "print(pd.unique(data[\"emotion\"]))\n",
    "# data are 48x48 pixel images of faces \n",
    "# expresions are coded as 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "images = data[\"image\"].to_numpy()\n",
    "target = data[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [] \n",
    "ys = [] \n",
    "labels = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35882/35882 [1:00:38<00:00,  9.86it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ion()\n",
    "f = plt.figure()\n",
    "for i in tqdm(range(len(images))):\n",
    "    im = images[i]\n",
    "    im_data = np.array([np.uint8(val) for val in im.split(' ')]).reshape((48, 48))\n",
    "    plt.clf()\n",
    "    plt.imshow(im_data, cmap=\"gray\")\n",
    "    plt.savefig(\"./_temp.png\")\n",
    "    points = np.array(getLandmarks(\"./_temp.png\"))\n",
    "    if len(points) > 0: \n",
    "        x = points[:, 0]\n",
    "        y = -points[:, 1]\n",
    "        x_cm = np.mean(x)\n",
    "        y_cm = np.mean(y)\n",
    "\n",
    "        # center by the average\n",
    "        x = x - x_cm\n",
    "        y = y - y_cm\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        labels.append(target[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(xs)\n",
    "ys = np.array(ys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 595.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#d_xs= pd.DataFrame(xs, columns=['x_{}'.format(i) for i in range(len(xs[0]))])\n",
    "#d_ys= pd.DataFrame(xs, columns=['y_{}'.format(i) for i in range(len(ys[0]))])\n",
    "#d_labels = pd.DataFrame(labels, columns=['label'])\n",
    "landmark_data = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(xs.shape[1])):\n",
    "    landmark_data['x_{}'.format(i)] = xs[:, i]\n",
    "    landmark_data['y_{}'.format(i)] = ys[:, i]\n",
    "\n",
    "landmark_data['target'] = labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>...</th>\n",
       "      <th>y_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>y_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>y_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>y_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>y_67</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.435410</td>\n",
       "      <td>0.222661</td>\n",
       "      <td>-0.429431</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>-0.412437</td>\n",
       "      <td>-0.009317</td>\n",
       "      <td>-0.385777</td>\n",
       "      <td>-0.119490</td>\n",
       "      <td>-0.341571</td>\n",
       "      <td>-0.220299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175001</td>\n",
       "      <td>0.140915</td>\n",
       "      <td>-0.182251</td>\n",
       "      <td>0.045438</td>\n",
       "      <td>-0.205269</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>-0.210923</td>\n",
       "      <td>-0.043349</td>\n",
       "      <td>-0.206142</td>\n",
       "      <td>3.049335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.073389</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>0.068232</td>\n",
       "      <td>0.057149</td>\n",
       "      <td>0.066505</td>\n",
       "      <td>0.052284</td>\n",
       "      <td>0.065696</td>\n",
       "      <td>0.050502</td>\n",
       "      <td>0.060208</td>\n",
       "      <td>0.048720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.030239</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>2.031198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.768242</td>\n",
       "      <td>-0.039152</td>\n",
       "      <td>-0.739966</td>\n",
       "      <td>-0.132942</td>\n",
       "      <td>-0.703257</td>\n",
       "      <td>-0.226557</td>\n",
       "      <td>-0.658352</td>\n",
       "      <td>-0.328819</td>\n",
       "      <td>-0.582085</td>\n",
       "      <td>-0.435501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286550</td>\n",
       "      <td>0.026039</td>\n",
       "      <td>-0.283568</td>\n",
       "      <td>-0.093550</td>\n",
       "      <td>-0.331650</td>\n",
       "      <td>-0.135036</td>\n",
       "      <td>-0.344079</td>\n",
       "      <td>-0.170338</td>\n",
       "      <td>-0.330725</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.481282</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>-0.471440</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>-0.453561</td>\n",
       "      <td>-0.042326</td>\n",
       "      <td>-0.428508</td>\n",
       "      <td>-0.150394</td>\n",
       "      <td>-0.381592</td>\n",
       "      <td>-0.250842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194751</td>\n",
       "      <td>0.118027</td>\n",
       "      <td>-0.203317</td>\n",
       "      <td>0.028267</td>\n",
       "      <td>-0.223683</td>\n",
       "      <td>-0.015461</td>\n",
       "      <td>-0.229859</td>\n",
       "      <td>-0.062107</td>\n",
       "      <td>-0.224562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.437461</td>\n",
       "      <td>0.223845</td>\n",
       "      <td>-0.430372</td>\n",
       "      <td>0.106297</td>\n",
       "      <td>-0.412653</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>-0.386475</td>\n",
       "      <td>-0.118411</td>\n",
       "      <td>-0.342332</td>\n",
       "      <td>-0.219446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175023</td>\n",
       "      <td>0.140249</td>\n",
       "      <td>-0.183034</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>-0.204752</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.043853</td>\n",
       "      <td>-0.205345</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.393713</td>\n",
       "      <td>0.264702</td>\n",
       "      <td>-0.389404</td>\n",
       "      <td>0.141913</td>\n",
       "      <td>-0.372340</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>-0.345187</td>\n",
       "      <td>-0.087535</td>\n",
       "      <td>-0.303687</td>\n",
       "      <td>-0.189007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155046</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>-0.162560</td>\n",
       "      <td>0.063429</td>\n",
       "      <td>-0.186202</td>\n",
       "      <td>0.017744</td>\n",
       "      <td>-0.191509</td>\n",
       "      <td>-0.026374</td>\n",
       "      <td>-0.187152</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.106288</td>\n",
       "      <td>0.501977</td>\n",
       "      <td>-0.133505</td>\n",
       "      <td>0.347150</td>\n",
       "      <td>-0.136603</td>\n",
       "      <td>0.190817</td>\n",
       "      <td>-0.116464</td>\n",
       "      <td>0.083028</td>\n",
       "      <td>-0.103498</td>\n",
       "      <td>-0.019345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072982</td>\n",
       "      <td>0.269701</td>\n",
       "      <td>-0.048036</td>\n",
       "      <td>0.159273</td>\n",
       "      <td>-0.097641</td>\n",
       "      <td>0.116056</td>\n",
       "      <td>-0.104646</td>\n",
       "      <td>0.082203</td>\n",
       "      <td>-0.102866</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x_0           y_0           x_1           y_1           x_2  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean      -0.435410      0.222661     -0.429431      0.105320     -0.412437   \n",
       "std        0.073389      0.064486      0.068232      0.057149      0.066505   \n",
       "min       -0.768242     -0.039152     -0.739966     -0.132942     -0.703257   \n",
       "25%       -0.481282      0.181268     -0.471440      0.069432     -0.453561   \n",
       "50%       -0.437461      0.223845     -0.430372      0.106297     -0.412653   \n",
       "75%       -0.393713      0.264702     -0.389404      0.141913     -0.372340   \n",
       "max       -0.106288      0.501977     -0.133505      0.347150     -0.136603   \n",
       "\n",
       "                y_2           x_3           y_3           x_4           y_4  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean      -0.009317     -0.385777     -0.119490     -0.341571     -0.220299   \n",
       "std        0.052284      0.065696      0.050502      0.060208      0.048720   \n",
       "min       -0.226557     -0.658352     -0.328819     -0.582085     -0.435501   \n",
       "25%       -0.042326     -0.428508     -0.150394     -0.381592     -0.250842   \n",
       "50%       -0.008215     -0.386475     -0.118411     -0.342332     -0.219446   \n",
       "75%        0.023557     -0.345187     -0.087535     -0.303687     -0.189007   \n",
       "max        0.190817     -0.116464      0.083028     -0.103498     -0.019345   \n",
       "\n",
       "       ...          y_63          x_64          y_64          x_65  \\\n",
       "count  ...  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean   ...     -0.175001      0.140915     -0.182251      0.045438   \n",
       "std    ...      0.029053      0.033105      0.030246      0.030239   \n",
       "min    ...     -0.286550      0.026039     -0.283568     -0.093550   \n",
       "25%    ...     -0.194751      0.118027     -0.203317      0.028267   \n",
       "50%    ...     -0.175023      0.140249     -0.183034      0.045812   \n",
       "75%    ...     -0.155046      0.163308     -0.162560      0.063429   \n",
       "max    ...     -0.072982      0.269701     -0.048036      0.159273   \n",
       "\n",
       "               y_65          x_66          y_66          x_67          y_67  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean      -0.205269      0.000994     -0.210923     -0.043349     -0.206142   \n",
       "std        0.028254      0.030334      0.028851      0.030634      0.028011   \n",
       "min       -0.331650     -0.135036     -0.344079     -0.170338     -0.330725   \n",
       "25%       -0.223683     -0.015461     -0.229859     -0.062107     -0.224562   \n",
       "50%       -0.204752      0.000649     -0.210313     -0.043853     -0.205345   \n",
       "75%       -0.186202      0.017744     -0.191509     -0.026374     -0.187152   \n",
       "max       -0.097641      0.116056     -0.104646      0.082203     -0.102866   \n",
       "\n",
       "             target  \n",
       "count  26553.000000  \n",
       "mean       3.049335  \n",
       "std        2.031198  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        3.000000  \n",
       "75%        5.000000  \n",
       "max        6.000000  \n",
       "\n",
       "[8 rows x 137 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_data.to_csv('/media/john/Data/datasets/facial-expressions/facial_landmarks.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's add the pariwise distances to the datasetr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26553/26553 [03:38<00:00, 121.74it/s]\n"
     ]
    }
   ],
   "source": [
    "distances = []\n",
    "for i in tqdm(range(xs.shape[0])): \n",
    "    d = {}\n",
    "    for j in range(ys.shape[1]): \n",
    "        for k in range(xs.shape[1]): \n",
    "            if j < k: \n",
    "                d[\"{0},{1}\".format(j, k)] = np.sqrt((xs[i, j]-xs[i, k])**2+(ys[i, j]-ys[i, k])**2)\n",
    "    distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.DataFrame(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0,1</th>\n",
       "      <th>0,2</th>\n",
       "      <th>0,3</th>\n",
       "      <th>0,4</th>\n",
       "      <th>0,5</th>\n",
       "      <th>0,6</th>\n",
       "      <th>0,7</th>\n",
       "      <th>0,8</th>\n",
       "      <th>0,9</th>\n",
       "      <th>0,10</th>\n",
       "      <th>...</th>\n",
       "      <th>63,64</th>\n",
       "      <th>63,65</th>\n",
       "      <th>63,66</th>\n",
       "      <th>63,67</th>\n",
       "      <th>64,65</th>\n",
       "      <th>64,66</th>\n",
       "      <th>64,67</th>\n",
       "      <th>65,66</th>\n",
       "      <th>65,67</th>\n",
       "      <th>66,67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "      <td>26553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.118227</td>\n",
       "      <td>0.234484</td>\n",
       "      <td>0.347626</td>\n",
       "      <td>0.455292</td>\n",
       "      <td>0.555964</td>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.735108</td>\n",
       "      <td>0.798760</td>\n",
       "      <td>0.847171</td>\n",
       "      <td>0.872511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.063090</td>\n",
       "      <td>0.098968</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>0.146772</td>\n",
       "      <td>0.189173</td>\n",
       "      <td>0.045150</td>\n",
       "      <td>0.089402</td>\n",
       "      <td>0.044940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.027576</td>\n",
       "      <td>0.038933</td>\n",
       "      <td>0.048508</td>\n",
       "      <td>0.056394</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.071104</td>\n",
       "      <td>0.074376</td>\n",
       "      <td>0.073347</td>\n",
       "      <td>0.066840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.024939</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.034340</td>\n",
       "      <td>0.041057</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.009241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.119829</td>\n",
       "      <td>0.179518</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>0.314218</td>\n",
       "      <td>0.383151</td>\n",
       "      <td>0.438955</td>\n",
       "      <td>0.476439</td>\n",
       "      <td>0.523731</td>\n",
       "      <td>0.573681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.014404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.108985</td>\n",
       "      <td>0.217002</td>\n",
       "      <td>0.322989</td>\n",
       "      <td>0.424504</td>\n",
       "      <td>0.519783</td>\n",
       "      <td>0.607214</td>\n",
       "      <td>0.688824</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>0.799753</td>\n",
       "      <td>0.830160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.045062</td>\n",
       "      <td>0.082126</td>\n",
       "      <td>0.080148</td>\n",
       "      <td>0.119669</td>\n",
       "      <td>0.158712</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.077110</td>\n",
       "      <td>0.038665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.234916</td>\n",
       "      <td>0.347863</td>\n",
       "      <td>0.455167</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.647873</td>\n",
       "      <td>0.733952</td>\n",
       "      <td>0.798436</td>\n",
       "      <td>0.847109</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098409</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.187553</td>\n",
       "      <td>0.044927</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.044506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.127953</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>0.372931</td>\n",
       "      <td>0.486719</td>\n",
       "      <td>0.592649</td>\n",
       "      <td>0.690540</td>\n",
       "      <td>0.781950</td>\n",
       "      <td>0.847608</td>\n",
       "      <td>0.894604</td>\n",
       "      <td>0.915558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119406</td>\n",
       "      <td>0.055588</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>0.111931</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.173199</td>\n",
       "      <td>0.218791</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>0.050936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.180196</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>0.516114</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.797659</td>\n",
       "      <td>0.930707</td>\n",
       "      <td>1.052071</td>\n",
       "      <td>1.134341</td>\n",
       "      <td>1.182139</td>\n",
       "      <td>1.205863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220661</td>\n",
       "      <td>0.203485</td>\n",
       "      <td>0.226880</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.236162</td>\n",
       "      <td>0.308884</td>\n",
       "      <td>0.379528</td>\n",
       "      <td>0.082450</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>0.081735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0,1           0,2           0,3           0,4           0,5  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean       0.118227      0.234484      0.347626      0.455292      0.555964   \n",
       "std        0.014558      0.027576      0.038933      0.048508      0.056394   \n",
       "min        0.058470      0.119829      0.179518      0.244604      0.314218   \n",
       "25%        0.108985      0.217002      0.322989      0.424504      0.519783   \n",
       "50%        0.118555      0.234916      0.347863      0.455167      0.555689   \n",
       "75%        0.127953      0.252563      0.372931      0.486719      0.592649   \n",
       "max        0.180196      0.351322      0.516114      0.668612      0.797659   \n",
       "\n",
       "                0,6           0,7           0,8           0,9          0,10  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean       0.648621      0.735108      0.798760      0.847171      0.872511   \n",
       "std        0.064372      0.071104      0.074376      0.073347      0.066840   \n",
       "min        0.383151      0.438955      0.476439      0.523731      0.573681   \n",
       "25%        0.607214      0.688824      0.750556      0.799753      0.830160   \n",
       "50%        0.647873      0.733952      0.798436      0.847109      0.873160   \n",
       "75%        0.690540      0.781950      0.847608      0.894604      0.915558   \n",
       "max        0.930707      1.052071      1.134341      1.182139      1.205863   \n",
       "\n",
       "       ...         63,64         63,65         63,66         63,67  \\\n",
       "count  ...  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean   ...      0.099341      0.035498      0.063090      0.098968   \n",
       "std    ...      0.031458      0.030030      0.024939      0.024326   \n",
       "min    ...      0.001424      0.000030      0.013649      0.034249   \n",
       "25%    ...      0.079257      0.010254      0.045062      0.082126   \n",
       "50%    ...      0.098409      0.026596      0.055411      0.095004   \n",
       "75%    ...      0.119406      0.055588      0.076628      0.111931   \n",
       "max    ...      0.220661      0.203485      0.226880      0.249997   \n",
       "\n",
       "              64,65         64,66         64,67         65,66         65,67  \\\n",
       "count  26553.000000  26553.000000  26553.000000  26553.000000  26553.000000   \n",
       "mean       0.103060      0.146772      0.189173      0.045150      0.089402   \n",
       "std        0.034340      0.041057      0.045891      0.009378      0.018082   \n",
       "min        0.001803      0.006011      0.011927      0.011344      0.028279   \n",
       "25%        0.080148      0.119669      0.158712      0.038690      0.077110   \n",
       "50%        0.100944      0.144693      0.187553      0.044927      0.088761   \n",
       "75%        0.124959      0.173199      0.218791      0.051281      0.101074   \n",
       "max        0.236162      0.308884      0.379528      0.082450      0.159046   \n",
       "\n",
       "              66,67  \n",
       "count  26553.000000  \n",
       "mean       0.044940  \n",
       "std        0.009241  \n",
       "min        0.014404  \n",
       "25%        0.038665  \n",
       "50%        0.044506  \n",
       "75%        0.050936  \n",
       "max        0.081735  \n",
       "\n",
       "[8 rows x 2278 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>...</th>\n",
       "      <th>63,64</th>\n",
       "      <th>63,65</th>\n",
       "      <th>63,66</th>\n",
       "      <th>63,67</th>\n",
       "      <th>64,65</th>\n",
       "      <th>64,66</th>\n",
       "      <th>64,67</th>\n",
       "      <th>65,66</th>\n",
       "      <th>65,67</th>\n",
       "      <th>66,67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.361885</td>\n",
       "      <td>0.335080</td>\n",
       "      <td>-0.386728</td>\n",
       "      <td>0.224464</td>\n",
       "      <td>-0.398756</td>\n",
       "      <td>0.110744</td>\n",
       "      <td>-0.387836</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>-0.356529</td>\n",
       "      <td>-0.103846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062529</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.077767</td>\n",
       "      <td>0.070583</td>\n",
       "      <td>0.103614</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.033093</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.038015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.434816</td>\n",
       "      <td>0.256265</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>0.129823</td>\n",
       "      <td>-0.390123</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>-0.351564</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>-0.293719</td>\n",
       "      <td>-0.212471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109040</td>\n",
       "      <td>0.041550</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.102239</td>\n",
       "      <td>0.129379</td>\n",
       "      <td>0.173443</td>\n",
       "      <td>0.210827</td>\n",
       "      <td>0.047436</td>\n",
       "      <td>0.090745</td>\n",
       "      <td>0.044419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.516714</td>\n",
       "      <td>0.275315</td>\n",
       "      <td>-0.516913</td>\n",
       "      <td>0.145745</td>\n",
       "      <td>-0.511237</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>-0.484466</td>\n",
       "      <td>-0.106841</td>\n",
       "      <td>-0.427562</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.030629</td>\n",
       "      <td>0.058918</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>0.078055</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.053996</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.395190</td>\n",
       "      <td>0.201027</td>\n",
       "      <td>-0.372570</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>-0.341578</td>\n",
       "      <td>-0.019932</td>\n",
       "      <td>-0.310975</td>\n",
       "      <td>-0.121200</td>\n",
       "      <td>-0.273600</td>\n",
       "      <td>-0.220257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105785</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>0.058116</td>\n",
       "      <td>0.103752</td>\n",
       "      <td>0.106247</td>\n",
       "      <td>0.161330</td>\n",
       "      <td>0.209041</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.103237</td>\n",
       "      <td>0.049085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.403541</td>\n",
       "      <td>0.223896</td>\n",
       "      <td>-0.400538</td>\n",
       "      <td>0.119213</td>\n",
       "      <td>-0.391955</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>-0.383610</td>\n",
       "      <td>-0.093439</td>\n",
       "      <td>-0.359848</td>\n",
       "      <td>-0.189248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094069</td>\n",
       "      <td>0.043715</td>\n",
       "      <td>0.064825</td>\n",
       "      <td>0.091647</td>\n",
       "      <td>0.089107</td>\n",
       "      <td>0.131186</td>\n",
       "      <td>0.168268</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.037884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26548</th>\n",
       "      <td>-0.431805</td>\n",
       "      <td>0.230261</td>\n",
       "      <td>-0.427210</td>\n",
       "      <td>0.115674</td>\n",
       "      <td>-0.410621</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>-0.385127</td>\n",
       "      <td>-0.106340</td>\n",
       "      <td>-0.351549</td>\n",
       "      <td>-0.200867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>0.029198</td>\n",
       "      <td>0.043779</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>0.101016</td>\n",
       "      <td>0.136772</td>\n",
       "      <td>0.172653</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.036173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26549</th>\n",
       "      <td>-0.430665</td>\n",
       "      <td>0.273707</td>\n",
       "      <td>-0.435900</td>\n",
       "      <td>0.152648</td>\n",
       "      <td>-0.423922</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>-0.406926</td>\n",
       "      <td>-0.077023</td>\n",
       "      <td>-0.376530</td>\n",
       "      <td>-0.172103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.032361</td>\n",
       "      <td>0.063891</td>\n",
       "      <td>0.081533</td>\n",
       "      <td>0.112641</td>\n",
       "      <td>0.144942</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.032316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26550</th>\n",
       "      <td>-0.385719</td>\n",
       "      <td>0.148835</td>\n",
       "      <td>-0.371583</td>\n",
       "      <td>0.045978</td>\n",
       "      <td>-0.344131</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.309499</td>\n",
       "      <td>-0.157787</td>\n",
       "      <td>-0.258393</td>\n",
       "      <td>-0.247109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093643</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.043653</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>0.095277</td>\n",
       "      <td>0.131146</td>\n",
       "      <td>0.163317</td>\n",
       "      <td>0.035934</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>0.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26551</th>\n",
       "      <td>-0.449453</td>\n",
       "      <td>0.221202</td>\n",
       "      <td>-0.462436</td>\n",
       "      <td>0.106291</td>\n",
       "      <td>-0.461007</td>\n",
       "      <td>-0.011399</td>\n",
       "      <td>-0.450873</td>\n",
       "      <td>-0.121879</td>\n",
       "      <td>-0.415810</td>\n",
       "      <td>-0.220654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105193</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.047578</td>\n",
       "      <td>0.088008</td>\n",
       "      <td>0.107903</td>\n",
       "      <td>0.150057</td>\n",
       "      <td>0.191128</td>\n",
       "      <td>0.042765</td>\n",
       "      <td>0.083519</td>\n",
       "      <td>0.041093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26552</th>\n",
       "      <td>-0.490338</td>\n",
       "      <td>0.135233</td>\n",
       "      <td>-0.461107</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>-0.422966</td>\n",
       "      <td>-0.090295</td>\n",
       "      <td>-0.376117</td>\n",
       "      <td>-0.196937</td>\n",
       "      <td>-0.316886</td>\n",
       "      <td>-0.299452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093610</td>\n",
       "      <td>0.053181</td>\n",
       "      <td>0.080515</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>0.094086</td>\n",
       "      <td>0.148428</td>\n",
       "      <td>0.202178</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.110943</td>\n",
       "      <td>0.057175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26553 rows × 2415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_0       y_0       x_1       y_1       x_2       y_2       x_3  \\\n",
       "0     -0.361885  0.335080 -0.386728  0.224464 -0.398756  0.110744 -0.387836   \n",
       "1     -0.434816  0.256265 -0.418404  0.129823 -0.390123  0.008268 -0.351564   \n",
       "2     -0.516714  0.275315 -0.516913  0.145745 -0.511237  0.016095 -0.484466   \n",
       "3     -0.395190  0.201027 -0.372570  0.086306 -0.341578 -0.019932 -0.310975   \n",
       "4     -0.403541  0.223896 -0.400538  0.119213 -0.391955  0.011448 -0.383610   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26548 -0.431805  0.230261 -0.427210  0.115674 -0.410621  0.003644 -0.385127   \n",
       "26549 -0.430665  0.273707 -0.435900  0.152648 -0.423922  0.034017 -0.406926   \n",
       "26550 -0.385719  0.148835 -0.371583  0.045978 -0.344131 -0.057797 -0.309499   \n",
       "26551 -0.449453  0.221202 -0.462436  0.106291 -0.461007 -0.011399 -0.450873   \n",
       "26552 -0.490338  0.135233 -0.461107  0.017911 -0.422966 -0.090295 -0.376117   \n",
       "\n",
       "            y_3       x_4       y_4  ...     63,64     63,65     63,66  \\\n",
       "0     -0.001191 -0.356529 -0.103846  ...  0.062529  0.008148  0.041225   \n",
       "1     -0.108422 -0.293719 -0.212471  ...  0.109040  0.041550  0.069430   \n",
       "2     -0.106841 -0.427562 -0.204909  ...  0.021168  0.005296  0.030629   \n",
       "3     -0.121200 -0.273600 -0.220257  ...  0.105785  0.014016  0.058116   \n",
       "4     -0.093439 -0.359848 -0.189248  ...  0.094069  0.043715  0.064825   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26548 -0.106340 -0.351549 -0.200867  ...  0.107333  0.029198  0.043779   \n",
       "26549 -0.077023 -0.376530 -0.172103  ...  0.082943  0.006964  0.032361   \n",
       "26550 -0.157787 -0.258393 -0.247109  ...  0.093643  0.020915  0.043653   \n",
       "26551 -0.121879 -0.415810 -0.220654  ...  0.105193  0.019638  0.047578   \n",
       "26552 -0.196937 -0.316886 -0.299452  ...  0.093610  0.053181  0.080515   \n",
       "\n",
       "          63,67     64,65     64,66     64,67     65,66     65,67     66,67  \n",
       "0      0.077767  0.070583  0.103614  0.140187  0.033093  0.069880  0.038015  \n",
       "1      0.102239  0.129379  0.173443  0.210827  0.047436  0.090745  0.044419  \n",
       "2      0.058918  0.024900  0.048688  0.078055  0.025420  0.053996  0.029483  \n",
       "3      0.103752  0.106247  0.161330  0.209041  0.055083  0.103237  0.049085  \n",
       "4      0.091647  0.089107  0.131186  0.168268  0.042081  0.079379  0.037884  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "26548  0.072904  0.101016  0.136772  0.172653  0.035764  0.071797  0.036173  \n",
       "26549  0.063891  0.081533  0.112641  0.144942  0.031477  0.063721  0.032316  \n",
       "26550  0.072255  0.095277  0.131146  0.163317  0.035934  0.068540  0.032898  \n",
       "26551  0.088008  0.107903  0.150057  0.191128  0.042765  0.083519  0.041093  \n",
       "26552  0.121135  0.094086  0.148428  0.202178  0.054948  0.110943  0.057175  \n",
       "\n",
       "[26553 rows x 2415 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_data.join(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_data.to_csv('/media/john/Data/datasets/facial-expressions/facial_landmarks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-Learning Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard sci-kit learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# classification models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder # for categorical variables\n",
    "from tqdm import tqdm # for progress bar\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import joblib # for pickeling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26553, 2278)\n",
      "Index(['0,1', '0,2', '0,3', '0,4', '0,5', '0,6', '0,7', '0,8', '0,9', '0,10',\n",
      "       ...\n",
      "       '63,64', '63,65', '63,66', '63,67', '64,65', '64,66', '64,67', '65,66',\n",
      "       '65,67', '66,67'],\n",
      "      dtype='object', length=2278)\n"
     ]
    }
   ],
   "source": [
    "# define the inputs as unique distances\n",
    "inputs = dist_df.to_numpy()\n",
    "dist_ids = dist_df.columns\n",
    "print(inputs.shape)\n",
    "print(dist_ids)\n",
    "# there are 2 thousand unique distance pairs \n",
    "# and there are 26 thousand datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a list of classifiers to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = [\"K_Nearest_Neighbors\",\n",
    "                    \"Decision_Tree\",\n",
    "                    \"Random_Forest\",\n",
    "                    \"MLP_Neural_Net\",\n",
    "                    \"AdaBoost\",\n",
    "                    \"Naive_Bayes\",\n",
    "                    \"Quadratic_Discriminant_Analysis\",\n",
    "                    \"Linear_SVM\",\n",
    "                    \"RBF_SVM\",\n",
    "                    \"Gaussian_Process\"]\n",
    "\n",
    "\n",
    "# following example found at: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "classifiers = [\n",
    "                KNeighborsClassifier(2),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                MLPClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "                GaussianNB(),\n",
    "                QuadraticDiscriminantAnalysis(),\n",
    "                SVC(kernel=\"linear\"),\n",
    "                SVC(),\n",
    "                GaussianProcessClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22570, 2278) (3983, 2278)\n",
      "(22570,) (3983,)\n"
     ]
    }
   ],
   "source": [
    "# break up dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, landmark_data.loc[:, 'target'], test_size=.15, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on K_Nearest_Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [06:25<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.5719307054983681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [06:27<58:11, 387.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Decision_Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [12:24<58:11, 387.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.5992970123022847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [12:24<50:28, 378.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random_Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [19:16<50:28, 378.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.6876726085864926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [19:17<45:23, 389.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on MLP_Neural_Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [29:38<45:23, 389.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.42656289229224204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [29:39<45:51, 458.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [41:17<44:12, 530.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.4112478031634446\n",
      "Working on Naive_Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [41:18<24:46, 371.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.33642982676374594\n",
      "Working on Quadratic_Discriminant_Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      " 60%|██████    | 6/10 [42:31<24:46, 371.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.64925935224705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [42:32<14:06, 282.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Linear_SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:12:35<14:06, 282.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t accuracy: 0.49158925433090633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:12:36<24:37, 738.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on RBF_SVM\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "#go through the models\n",
    "with open('model_comparison.txt', 'w') as f:\n",
    "    for k in tqdm(range(len(classifiers))):\n",
    "        tqdm.write(\"Working on {}\".format(classifier_names[k]))\n",
    "        clf = classifiers[k]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # record accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tqdm.write(\"\\t accuracy: {}\".format(accuracy))\n",
    "        f.write(\"Model {0} fit with accuracy {1}\\n\".format(classifier_names[k], accuracy))\n",
    "\n",
    "        accuracy_dict[classifier_names[k]] = accuracy\n",
    "\n",
    "        # record confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure()\n",
    "        plt.imshow(cm, cmap='Blues')\n",
    "        target_names = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation='vertical')\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                plt.text(j, i, \"{0:.2f}%\".format(100*(cm[i, j])/sum(cm[i,:])),\n",
    "                        horizontalalignment=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > (cm.max()/2) else \"black\")\n",
    "        plt.savefig('./models/evaluation/{}-expression-model_confusion matrix.png'.format(classifier_names[k]), format='png')\n",
    "        plt.title(\"{0}  Accuracy:{1}\".format(classifier_names[k], round(accuracy, 5)))\n",
    "        joblib.dump(clf, './models/{}.pkl'.format(classifier_names[k]))\n",
    "\n",
    "\n",
    "\n",
    "for key in accuracy_dict:\n",
    "    print(key, round(accuracy_dict[key], 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
